---
title: "Ensayo"
author: "Julian Cruz"
output: 
  pdf_document:
    keep_tex: true
    toc: false
    number_sections: true
---


En la práctica las herramientas estadísticas tienen varios usos: uno de ellos consiste en la obtención de cifras globales que permitan entender sistemas y pronosticar estados futuros de los mismos analizando sus tendencias actuales. Esta labor la podemos observar en épocas de votaciones donde las firmas encuestadores realizan mediciones que dan un panorama electoral sucinto, y que, en diversos imaginarios, pronostican los giros democráticos de la sociedad.

Otro uso común de las herramientas estadísticas es la asignación de valores a individuos: puede ser que tengamos algunas mediciones de algunos individuos y con esta información asignemos valores al resto. Un ejemplo puede ser la asignación de penas a las personas declaradas culpables de un delito; si una persona comete un delito, el número de años en la cárcel debe estar en concordancia con las penas aplicadas a las personas que ya fueron condenadas.

También puede ser que sea necesario generar valores para todos. Generalmente estos valores, numéricos o categóricos, reflejan o miden algún rasgo o característica particular de cada individuo. Un ejemplo de este uso es la asignación de un estrato socioeconómico a cada predio en Bogotá, que busca clasificar los predios en 6 grupos con comportamientos económicos similares con el fin de organizar subsidios e impuestos entre otros.

Los primeros se enfocan en encontrar un número, un porcentaje o una cifra que "hable" por sí sola; los segundos se centran en que los valores asignados tengan algún tipo de coherencia interna, o bien con los datos anteriores o bien con el rasgo que se intenta resumir. En el primer caso estamos hablando de estudios de tipo explicativo y en el segundo de tipo predictivo. 

Muchas veces en los estudios de carácter explicativo no resulta viable consultar a todos los individuos y los análisis se realizan con muestras tomadas de la población. Con este fin se aplican técnicas inferenciales que, mediante teoría de la medida y de la probabilidad, proporcionan intervalos de confianza y de credibilidad, rangos en los cuales se sitúa el parámetro poblacional con una probabilidad determinada bajo el supuesto de que la muestra ha sido tomada aleatoriamente. El problema población-muestra ha sido la motivación principal del desarrollo de estimaciones puntuales, por intervalo, pruebas de hipótesis y conceptos centrales en la estadística como la significancia y la representatividad.

Uno de los desarrollos estadísticos dentro de este enfoque es el muestreo. Se trata de un conjunto de técnicas y teorías que nos muestran en detalle cómo obtener una muestra representativa dependiendo de las características de la población sobre la que se va a realizar el proceso inferencial. Otro es el diseño de experimentos, que nos explica como la asignación aleatoria de factores controlables a los individuos de la muestra puede concluir causalidad. Temas obligatorios al abordar en detalle el problema población-muestra, que retomaremos probablemente en otro punto.

En los estudios de carácter predictivo no siempre se tiene este problema, en el ejemplo de las personas condenadas y en el de los predios se tiene la población completa o por lo menos no hay claridad respecto a un diseño muestral o a la necesidad de un proceso de tipo inferencial. Un escenario particular es el de los exámenes de estado: los jóvenes que finalizan los estudios básicos son convocados para presentar una prueba que mide sus capacidades en diversos campos; aquí hay un acceso, ciertamente inusual, a los datos de la población completa. Asignar un número o categoría a cada estudiante para medir sus capacidades en tópicos definidos tomando como insumo sus respuestas correctas e incorrectas, sin ambiciones inferenciales, es un proceso bastante complejo en sí mismo. Este problema lo denominaremos aprendizaje de los datos.

Así vemos como en una esquina se encuentran los estudios de tipo explicativo, centrados en los procesos de estimación del parámetro poblacional y en la otra se encuentran los estudios de tipo predictivo centrados en el ajuste del modelo a los datos. Hacer esta distinción puntual resulta necesario puesto que aún en ámbitos académicos no se distinguen los problemas claramente y en muchas ocasiones se utilizan las herramientas estadísticas inferenciales para realizar pronóstico y viceversa. En varios escenarios se dice que no es posible realizar pronóstico sin utilizar métodos inferenciales, se aplican pruebas de hipótesis a datos censales, se confunden parámetros poblacionales con parámetros teóricos o muestrales. ¿Qué sentido tiene la discusión entre la estimación maximoveriosimil y la estimación usando momentos cuando se ha garantizado acceso a los datos a nivel poblacional?
Distinguir el escenario de población-muestra y el escenario de aprendizaje de los datos es esencial para conocer el quehacer estadístico. Resulta preocupante ver como algunos miembros de la comunidad científica dan por sentado que la estadística es el estudio del problema población-muestra, invalidando otros métodos que, en otros ámbitos, han permitido grandes avances. El estudio de métodos estadísticos de pronóstico centrados más en el ajuste que en la inferencia no es una "pseudoestadística" sino un enfoque distinto de la misma.

Uno de los desacuerdos más profundos entre los dos contextos es el referente al valor de la interpretabilidad del resultado. Hay quienes exigen que todo resultado estadístico tenga una interpretación, otros se rehúsan a dar una interpretación a las cifras, dando por sentado que estas son, o deben ser, intuitivas. No obstante para discutir al respecto es necesario preguntarse por la interpretación misma, su significado y sus procesos.

Para indagar sobre el proceso interpretativo podemos comenzar con algunos ejemplos: El p valor de una prueba de hipótesis se puede interpretar como la probabilidad de cometer un error al rechazar la hipótesis nula, el coeficiente B_1 de una regresión logística entre dos variables binarias se puede interpretar como la razón de odds entre las mismas, la probabilidad de .5 de una moneda puede interpretarse como el número al cual tiende la proporción de aciertos al lanzar la moneda indefinidamente. El proceso interpretativo al rededor de un resultado estadístico está dado por la asignación de un significado en términos de los datos. No obstante es un proceso altamente complejo y subjetivo que en general presenta errores. Por ejemplo, asignarle un significado a la razón de odds, al coeficiente de variación, a la curtosis o al riesgo relativo en términos no estadísticos resulta en ocasiones bastante complicado. ¿Cómo se interpreta un coeficiente de correlación cercano a cero pero estadísticamente significativo?

Otro ejemplo es la asignación por parte de entidades estatales de un puntaje de bienestar (SISBEN) a cada ciudadano, que no tiene una interpretación directa. Un ciudadano común no sabe qué significa un puntaje de SISBEN de 3.5, sin embargo culturalmente se tiene el conocimiento de que las personas con un mayor puntaje tienen en su cotidiano unas condiciones muy diferentes a las personas de menores puntajes. En esto es posible decir que aunque no es posible asignar un significado a dicho puntaje el significado del mismo está dado de manera autónoma por el contexto. Lo mismo sucede con el estrato socioeconómico, los puntajes de las pruebas estatales, entre otros. La interpretabilidad directa en el problema de aprendizaje de los datos no sólo carece de valor sino que exigirla puede deteriorar los procesos algorítmicos propios del problema.

Así podemos asociar el problema de aprendizaje de los datos a una interpretación tácita, contextual y global que se desprende de las características de los individuos y los valores asignados a los mismos. A su vez los estudios de tipo explicativo propenden, como se dijo, por cifras globales que "hablen" por sí mismas por ello dependen de una interpretación directa que facilite la comprensión de los sistemas y la toma de decisiones.

De esta forma es posible observar dos usos habituales de la estadística, los estudios explicativos que se centran en la medición de parámetros poblacionales que definan tendencias globales y que en general necesitan procesos inferenciales y resutados directamente interpretables; y los estudios predictivos que asignan valores a los individuos, centrándose en la coherencia de los valores asignados con el comportamiento de los individuos y cuyos resultados presentan una interpretación indirecta necesariamente contextualizada.

La carta de navegación en un análisis estadístico debe responder por completo a los objetivos del mismo eligiendo las herramientas necesarias para resolver las preguntas que motivaron el mismo. En esto, ya a modo de conclusión, podemos decir que es inconveniente e incluso preocupante la reducción de la estadística al problema población-muestra, que el estudio de técnicas de pronóstico que suprimen total o parcialmente el enfoque inferencial es por lo menos tan importante como todo lo demás y que, en palabras de Benzecrí, el modelo debe seguir a los datos y no al revés.

http://magazine.amstat.org/blog/2015/02/01/statscience_feb2015/
http://www.springer.com/us/book/9781441997814
Statistical Science 2010, Vol. 25, No. 3, 289–310 DOI: 10.1214/10-STS330 c ©Institute of Mathematical Statistics, 2010 To Explain or to Predict? Galit Shmueli
