@article{Abraham,
abstract = {Data in many different fields come to practitioners through a process naturally described as functional. Although data are gathered as finite vector and may contain measurement errors, the functional form have to be taken into account. We propose a clustering procedure of such data emphasizing the functional nature of the objects. The new clustering method consists of two stages: fitting the functional data by B-splines and partitioning the estimated model coefficients using a k-means algorithm. Strong consistency of the clustering method is proved and a real-world example from food industry is given.},
author = {Abraham, C and Cornillon, P A and {Matzner L{\o}ber}, E and Molinari, N},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abraham et al. - 2003 - Unsupervised Curve Clustering using B Splines.pdf:pdf},
isbn = {1467-9469},
journal = {Scandinavian Journal of Statistics},
keywords = {b-splines,clustering,epi-convergence,functional data,k -means,partitioning},
number = {3},
pages = {581--595},
title = {{Unsupervised Curve Clustering using B Splines}},
volume = {30},
year = {2003}
}
@phdthesis{Acosta2015,
author = {Acosta, Juan Pablo},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Acosta - 2015 - Strategy for Multivariate Identification of Diferentially Expressed Genes in Microarray Data.pdf:pdf},
title = {{Strategy for Multivariate Identification of Diferentially Expressed Genes in Microarray Data}},
year = {2015}
}
@misc{AcostaPackage,
address = {Bogota, Colombia},
annote = {R package version 1.0.0},
author = {Acosta, Juan Pablo and Lopez-Kleine, Liliana},
title = {{{\{}acde{\}}: Artificial Components Detection of Differentially Expressed Genes}},
year = {2015}
}
@phdthesis{Aponte2012,
author = {Aponte, Leonardo},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aponte - 2012 - Propuesta de una prueba basada en permutaciones para la igualdad de K medias bajo heteroscedasticidad.pdf:pdf},
number = {c},
title = {{Propuesta de una prueba basada en permutaciones para la igualdad de K medias bajo heteroscedasticidad}},
year = {2012}
}
@article{Applegate2011,
abstract = {Multidimensional distributions are often used in data min- ing to describe and summarize di erent features of large datasets. It is natural to look for distinct classes in such datasets by clustering the data. A common approach entails the use of methods like k-means clustering. However, the k-means method inherently relies on the Euclidean metric in the embedded space and does not account for additional topology underlying the distribution. In this paper, we propose using Earth Mover Distance (EMD) to compare multidimensional distributions. For a n-bin histogram, the EMD is based on a solution to the transportation problem with time complexity O(n3 log n). To mitigate the high computational cost of EMD, we pro- pose an approximation that reduces the cost to linear time. Given the large size of our dataset a fast approximation is crucial for this application. Other notions of distances such as the information theo- retic Kullback-Leibler divergence and statistical 2 distance, account only for the correspondence between bins with the same index, and do not use information across bins, and are sensitive to bin size. A cross-bin distance measure like EMD is not a ected by binning di erences and meaningfully matches the perceptual notion of $\backslash$nearness". Our technique is simple, e cient and practical for clus- tering distributions. We demonstrate the use of EMD on a real-world application of analyzing 411,550 anonymous mo- bility usage patterns which are dened as distributions over a manifold. EMD allows us to represent inherent relation- ships in this space, and enables us to successfully cluster even sparse signatures.},
author = {Applegate, D and Dasu, T and Krishnan, S and Urbanek, S},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Applegate et al. - 2011 - Unsupervised Clustering of Multidimensional Distributions using Earth Mover Distance.pdf:pdf},
isbn = {9781450308137},
journal = {Kdd'11},
keywords = {Algorithms,Similarity measures},
pages = {636--644},
title = {{Unsupervised Clustering of Multidimensional Distributions using Earth Mover Distance}},
year = {2011}
}
@misc{Barrera2014,
author = {Barrera, Carlos and Correa, Juan},
booktitle = {Simposio Internacional de Estad{\{}{\'{i}}{\}}stica},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Barrera, Correa - 2014 - A proposal of clustering for functional data.pdf:pdf},
title = {{A proposal of clustering for functional data}},
url = {http://simposioestadistica.unal.edu.co/fileadmin/content/eventos/simposioestadistica/documentos/memorias/Memorias{\{}{\_}{\}}2014.rar http://simposioestadistica.unal.edu.co/fileadmin/content/eventos/simposioestadistica/documentos/memorias/Memorias{\_}2014.rar},
year = {2014}
}
@article{CARSWA,
annote = {Evaluaci{\'{o}}n de 10 pruebas distintas. Recopilaci{\'{o}}n.},
author = {Cramer, S. G. and Swanson, M. R.},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cramer, Swanson - 1973 - An Evaluation of Ten Pairwise Multiple Comparison Procedures by Monte Carlo Methos.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {341},
pages = {66--74},
title = {{An Evaluation of Ten Pairwise Multiple Comparison Procedures by Monte Carlo Methos}},
volume = {68},
year = {1973}
}
@article{DUNCAN,
author = {Duncan, D},
doi = {10.1002/0471667196.ess0146.pub2},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Duncan - 1955 - Multiple Range and Multiple F Tests.pdf:pdf},
isbn = {9780471667193},
journal = {Biometrics},
number = {1},
pages = {1--42},
title = {{Multiple Range and Multiple F Tests}},
volume = {11},
year = {1955}
}
@article{DUNN,
annote = {From Duplicate 2 (Multiple Comparisons Among Means - Dunn, O J)

Prueba de Dunn.},
author = {Dunn, O J},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dunn - 2014 - Multiple Comparisons Among Means.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {450},
pages = {52--64},
title = {{Multiple Comparisons Among Means}},
volume = {56},
year = {1961}
}
@article{Egozcue2006,
abstract = {The set of probability functions is a convex subset of L 1 and it does not have a linear space structure when using ordinary sum and multiplication by real constants. Moreover, difficulties arise when dealing with distances between densities. The crucial point is that usual distances are not invariant under relevant transformations of densities. To overcome these limitations, Aitchison's ideas on compositional data analysis are used, generalizing perturbation and power transformation, as well as the Aitchison inner product, to operations on probability density functions with support on a finite interval. With these operations at hand, it is shown that the set of bounded probability density functions on finite intervals is a pre-Hilbert space. A Hilbert space of densities, whose logarithm is square-integrable, is obtained as the natural completion of the pre-Hilbert space.},
author = {Egozcue, J J and Iaz-Barrero, J L and Pawlowsky-Glahn, V},
doi = {10.1007/s10114-005-0678-2},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Egozcue, Iaz-Barrero, Pawlowsky-Glahn - 2006 - Hilbert Space of Probability Density Functions Based on Aitchison Geometry.pdf:pdf},
journal = {Acta Mathematica Sinica, English Series Jul},
keywords = {42B05,Aitchison distance,Bayes' theorem,Fourier coefficients,Haar basis,Simplex},
number = {4},
pages = {1175--1182},
title = {{Hilbert Space of Probability Density Functions Based on Aitchison Geometry}},
volume = {22},
year = {2006}
}
@article{Friedman1937,
annote = {From Duplicate 2 (Use of Ranks to Avoid the Assumption of Normality Implicit in the Analysis of Variance - Friedman, Milton)

Prueba de Friedman},
author = {Friedman, Milton},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friedman - 1937 - Use of Ranks to Avoid the Assumption of Normality Implicit in the Analysis of Variance.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {200},
pages = {675--701},
title = {{Use of Ranks to Avoid the Assumption of Normality Implicit in the Analysis of Variance}},
volume = {32},
year = {1937}
}
@article{Garcia2010,
abstract = {Experimental analysis of the performance of a proposed method is a crucial and necessary task in an investigation. In this paper, we focus on the use of nonparametric statistical inference for analyzing the results obtained in an experiment design in the field of computational intelligence. We present a case study which involves a set of techniques in classification tasks and we study a set of nonparametric procedures useful to analyze the behavior of a method with respect to a set of algorithms, such as the framework in which a new proposal is developed. Particularly, we discuss some basic and advanced nonparametric approaches which improve the results offered by the Friedman test in some circumstances. A set of post hoc procedures for multiple comparisons is presented together with the computation of adjusted p-values. We also perform an experimental analysis for comparing their power, with the objective of detecting the advantages and disadvantages of the statistical tests described. We found that some aspects such as the number of algorithms, number of data sets and differences in performance offered by the control method are very influential in the statistical tests studied. Our final goal is to offer a complete guideline for the use of nonparametric statistical procedures for performing multiple comparisons in experimental studies. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
annote = {Mirar muy bien,},
author = {Garc{\'{i}}a, Salvador and Fern{\'{a}}ndez, Alberto and Luengo, Juli{\'{a}}n and Herrera, Francisco},
doi = {10.1016/j.ins.2009.12.010},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Garc{\'{i}}a et al. - 2010 - Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence.pdf:pdf},
isbn = {0020-0255},
issn = {00200255},
journal = {Information Sciences},
keywords = {Computational intelligence,Data mining,Fuzzy classification systems,Genetics-based machine learning,Multiple comparisons procedures,Nonparametric statistics,Statistical analysis},
number = {10},
pages = {2044--2064},
publisher = {Elsevier Inc.},
title = {{Advanced nonparametric tests for multiple comparisons in the design of experiments in computational intelligence and data mining: Experimental analysis of power}},
url = {http://dx.doi.org/10.1016/j.ins.2009.12.010},
volume = {180},
year = {2010}
}
@book{GIBBONS,
address = {New York},
annote = {From Duplicate 1 (Nonparametric statistical inference - Gibbons, J D)

Sustenta el uso no param{\'{e}}trico},
author = {Gibbons, J D and Chakraborti, S},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gibbons - 1992 - Nonparametric statistical inference.pdf:pdf},
isbn = {0824740521},
keywords = {Methods},
publisher = {Marcel Dekker},
title = {{Nonparametric Statistical Inference}},
year = {2003}
}
@article{GORDON,
annote = {From Duplicate 2 (A Review of Hierarchical Clasification - Gordon, A D)

Una revisi{\'{o}}n sobre clasificaci{\'{o}}n jer{\'{a}}rquica.},
author = {Gordon, A D},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gordon - 1987 - A Review of Hierarchical Clasification.pdf:pdf},
isbn = {0000000779},
journal = {Journal of the Royal Statistical Society},
keywords = {clinical trials,equivalence,ethics,power,prediction,prior distribution,range of,shrinkage,stopping rules,subjective probabilities},
number = {2},
pages = {119--137},
title = {{A Review of Hierarchical Clasification}},
volume = {150},
year = {1987}
}
@article{Gordon1987,
abstract = {JSTOR is a not-for-profit service that helps scholars, researchers, and students discover, use, and build upon a wide range of content in a trusted digital archive. We use information technology and tools to increase productivity and facilitate new forms of scholarship. For more information about JSTOR, please contact support@jstor.org. SUMMARY A review is presented of methods of summarizing the relationships within a set of objects by a set of hierarchically-nested classes of similar objects, representable by a rooted tree diagram. Material covered includes algorithms for obtaining tree diagrams, comments on the selection of appropriate methods of analysis and the validation of classifications, distributions of different types of tree, and consensus trees.},
author = {Gordon, A D and Gordont, A D},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gordon, Gordont - 1987 - A Review of Hierarchical Classification.pdf:pdf},
journal = {Source Journal of the Royal Statistical Society. Series A (General) J. R. Statist. Soc. A},
keywords = {CLASSIFICATION,CLUSTER ANALYSIS,CONSENSUS TREES,DENDROGRAMS,HIERARCHICAL CLASSIFICATION,N-TREES,ULTRAMETRIC INEQUALITY,VALIDATION},
number = {2},
pages = {119--137},
title = {{A Review of Hierarchical Classification}},
url = {http://www.jstor.org http://www.jstor.org/stable/2981629 http://www.jstor.org/page/},
volume = {150},
year = {1987}
}
@article{HARTIGAN,
annote = {From Duplicate 1 (A K - Means Clustering Algorithm - Hartigan, J A; Wong, M A)

Algoritmo de K-Means.},
author = {Hartigan, J A and Wong, M A},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hartigan, Wong - 1979 - A K - Means Clustering Algorithm.pdf:pdf},
isbn = {0000000779},
journal = {Journal of the Royal Statistical Society},
keywords = {clinical trials,equivalence,ethics,power,prediction,prior distribution,range of,shrinkage,stopping rules,subjective probabilities},
number = {1},
pages = {100--108},
title = {{A K - Means Clustering Algorithm}},
volume = {28},
year = {1979}
}
@techreport{EPMEANS,
author = {Henderson, Keith and Gallagher, Brian and Eliassi-rad, Tina},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Henderson, Gallagher, Eliassi-rad - 2015 - EP-MEANS An Efficient Nonparametric Clustering of Empirical Probability Distributions.pdf:pdf},
isbn = {9781450331968},
title = {{EP-MEANS: An Efficient Nonparametric Clustering of Empirical Probability Distributions}},
year = {2015}
}
@article{James,
abstract = {We develop a flexible model-based procedure for clustering functional data. The technique can be applied to all types of curve data but is particularly useful when individuals are observed at a sparse set of time points. In addition to producing final cluster assignments, the procedure generates predictions and confidence intervals for missing portions of curves. Our approach also provides many useful tools for evaluating the resulting models. Clustering can be assessed visually via low dimensional represen- tations of the curves, and the regions of greatest separation between clusters can be determined using a discriminant function. Finally, we extend the model to handle multiple functional and finite dimensional covariates and show how it can be applied to standard finite dimensional clustering problems involving missing data.},
author = {James, Gareth M and Sugar, Catherine A},
doi = {10.1198/016214503000189},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/James, Sugar - 2003 - Clustering for Sparsely Sampled Functional Data.pdf:pdf},
isbn = {0001689117171},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Curve estimation,Discriminant functions,Functional clustering,High dimensional data,Some key words},
number = {462},
pages = {397--408},
title = {{Clustering for Sparsely Sampled Functional Data}},
volume = {98},
year = {2003}
}
@article{Javier2015,
author = {Javier, Carlos and Causil, Barrera},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Javier, Causil - 2015 - Analysis of the elicited prior distributions using tools of functional data analysis.pdf:pdf},
title = {{Analysis of the elicited prior distributions using tools of functional data analysis}},
year = {2015}
}
@article{Joe1963,
annote = {Algoritmo jer{\'{a}}rquico de Ward.},
author = {Joe, H and Ward, Jr},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Joe, Ward - 1963 - Hierarchical Grouping to Optimize an Objective Function.pdf:pdf},
journal = {Journal of the American Statistical Association1},
number = {301},
pages = {236 -- 244},
title = {{Hierarchical Grouping to Optimize an Objective Function}},
volume = {58},
year = {1963}
}
@book{Jolliffe2002,
abstract = {Principal component analysis is central to the study of multivariate data. Although one of the earliest multivariate techniques it continues to be the subject of much research, ranging from new model- based approaches to algorithmic ideas from neural networks. It is extremely versatile with applications in many disciplines. The first edition of this book was the first comprehensive text written solely on principal component analysis. The second edition updates and substantially expands the original version, and is once again the definitive text on the subject. It includes core material, current research and a wide range of applications. Its length is nearly double that of the first edition. Researchers in statistics, or in other fields that use principal component analysis, will find that the book gives an authoritative yet accessible account of the subject. It is also a valuable resource for graduate courses in multivariate analysis. The book requires some knowledge of matrix algebra. Ian Jolliffe is Professor of Statistics at the University of Aberdeen. He is author or co-author of over 60 research papers and three other books. His research interests are broad, but aspects of principal component analysis have fascinated him and kept him busy for over 30 years.},
author = {Jolliffe, I T},
booktitle = {Encyclopedia of Statistics in Behavioral Science},
doi = {10.2307/1270093},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jolliffe - 2002 - Principal Component Analysis, Second Edition.pdf:pdf},
isbn = {0387954422},
issn = {00401706},
number = {3},
pages = {487},
pmid = {21435900},
title = {{Principal Component Analysis, Second Edition}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/0470013192.bsa501/full},
volume = {30},
year = {2002}
}
@article{Karypis1999,
abstract = {Clustering is a discovery process in data mining. It groups a set of data in a way that maximizes the similarity within clusters and minimizes the similarity between two different clusters. Many advanced algorithms have difficulty dealing with highly variable clusters that do not follow a preconceived model. By basing its selections on both interconnectivity and closeness, the Chameleon algorithm yields accurate results for these highly variable clusters. Existing algorithms use a static model of the clusters and do not use information about the nature of individual clusters as they are merged. Furthermore, one set of schemes (the CURE algorithm and related schemes) ignores the information about the aggregate interconnectivity of items in two clusters. Another set of schemes (the Rock algorithm, group averaging method, and related schemes) ignores information about the closeness of two clusters as defined by the similarity of the closest items across two clusters. By considering either interconnectivity or closeness only, these algorithms can select and merge the wrong pair of clusters. Chameleon's key feature is that it accounts for both interconnectivity and closeness in identifying the most similar pair of clusters. Chameleon finds the clusters in the data set by using a two-phase algorithm. During the first phase, Chameleon uses a graph partitioning algorithm to cluster the data items into several relatively small subclusters. During the second phase, it uses an algorithm to find the genuine clusters by repeatedly combining these subclusters},
author = {Karypis, George and Han, Eui-Hong and Kumar, Vipin},
doi = {10.1109/2.781637},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karypis, Han, Kumar - 1999 - Chameleon hierarchical clustering using dynamic modeling.pdf:pdf},
isbn = {0018-9162 VO - 32},
issn = {00189162},
journal = {Computer},
keywords = {Aggregates,CURE algorithm,Chameleon algorithm,Clustering algorithms,Earthquakes,Extraterrestrial measurements,Proteins,Rock algorithm,Seismology,Shape,advanced algorithms,aggregate interconnectivity,closeness,closest items,data analysis,data item clustering,data mining,data set,discovery process,dynamic modeling,graph partitioning algorithm,graph theory,hierarchical clustering,highly variable clusters,most similar pair,pattern clustering,subclusters,two-phase algorithm},
number = {8},
pages = {68--75},
pmid = {781637},
title = {{Chameleon: hierarchical clustering using dynamic modeling}},
volume = {32},
year = {1999}
}
@article{KWTEST,
annote = {From Duplicate 2 (Use of Ranks in One-Criterion Variance Analysis - Kruskal, William H; Wallis, W. Allen)

Prueba de Kruskall Wallis},
author = {Kruskal, W and Wallis, A},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kruskal, Wallis - 1952 - Use of Ranks in One-Criterion Variance Analysis.pdf:pdf},
journal = {Journal of the American Statistical Association},
number = {260},
pages = {583--621},
title = {{Use of Ranks in One-Criterion Variance Analysis}},
volume = {47},
year = {1952}
}
@article{Krzanowsky1987,
annote = {No s{\'{e}} para qu{\'{e}} pueda servir.},
author = {Krzanowsky, W J},
doi = {10.1002/0471667196.ess0146.pub2},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krzanowsky - 1987 - Cross - Validation in Principal Component Analysis.pdf:pdf},
isbn = {9780471667193},
journal = {Biometrics},
number = {3},
pages = {575 -- 584},
title = {{Cross - Validation in Principal Component Analysis}},
volume = {43},
year = {1987}
}
@book{LEBART,
address = {Paris},
author = {Lebart, L and Morineau, A and Piron, M},
publisher = {Dunod},
title = {{Statistique exploratorie multidimensionelle}},
year = {1995}
}
@article{Leon2010,
abstract = {In this paper, we present a scalable evolutionary algorithm for clustering large and dynamic data sets, called Scalable Evolutionary Clustering with Self Adaptive Genetic Operators (Scalable ECSAGO). The proposed evolutionary clustering algorithm can adapt its genetic operators rate while the evolution leads to the optimal centers of the clusters. The sizes of the clusters are estimated using a hybrid analytical optimization procedure. Moreover, a memorization factor is introduced in order to allow the algorithm to keep as much of the previously discovered knowledge about clusters and data summarization as desired. The proposed scalable ECSAGO algorithm is able to find accurate representations of the clusters on very large data sets of different sizes and dimensionality that might not fit in main memory, while maintaining the desirable properties of robustness to noise and automatic detection of the number of clusters. The algorithm is also useful for traking evolving cluster structures that change with the passage of time.},
annote = {Agrupaci{\'{o}}n basada en algoritmos gen{\'{e}}ticos.

Leer detenidamente y ver si se puede aplicar.},
author = {Le{\'{o}}n, Elizabeth and Nasraoui, Olfa and Gomez, Jonatan},
doi = {10.1109/CEC.2010.5586467},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Le{\'{o}}n, Nasraoui, Gomez - 2010 - Scalable evolutionary clustering algorithm with self adaptive genetic operators.pdf:pdf},
isbn = {9781424469109},
journal = {2010 IEEE World Congress on Computational Intelligence, WCCI 2010 - 2010 IEEE Congress on Evolutionary Computation, CEC 2010},
title = {{Scalable evolutionary clustering algorithm with self adaptive genetic operators}},
year = {2010}
}
@book{Montgomery2004,
address = {University of Arizona},
annote = {From Duplicate 2 (Dise{\~{n}}o y an{\'{a}}lisis de Experimentos - Montgomery, Douglas C.)

Sirve para sustentar los m{\'{e}}todos presentados},
author = {Montgomery, Douglas C.},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Montgomery - 2004 - Dise{\~{n}}o y an{\'{a}}lisis de Experimentos.pdf:pdf},
isbn = {968-18-6156-6},
pages = {692},
publisher = {John Wiley {\&} Sons},
title = {{Dise{\~{n}}o y an{\'{a}}lisis de Experimentos}},
year = {2004}
}
@article{Muller2006,
abstract = {We discuss Bayesian approaches to multiple comparison problems, using a decision theoretic perspective to critically compare competing approaches. We set up decision problems that lead to the use of FDR-based rules and generalizations. Alternative definitions of the probability model and the utility function lead to different rules and problem-specific adjustments. Using a loss function that controls realized FDR we derive an optimal Bayes rule that is a variation of the Benjamini and Hochberg (1995) procedure. The cutoff is based on increments in ordered posterior probabilities instead of ordered p- values. Throughout the discussion we take a Bayesian perspective. In particular, we focus on conditional expected FDR, conditional on the data. Variations of the probability model include explicit modeling for dependence. Variations of the utility function include weighting by the extent of a true negative and accounting for the impact in the final decision.},
annote = {FDR, leer y mirar cuidadosamente.},
author = {Muller, P and Parmigiani, Giovanni and Rice, Kenneth},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Muller, Parmigiani, Rice - 2006 - FDR and Bayesian multiple comparisons rules.pdf:pdf},
journal = {Bayesian Statistics 8},
keywords = {and phrases,decision problems,false,multiplicities},
number = {1995},
pages = {349--370},
title = {{FDR and Bayesian multiple comparisons rules}},
url = {http://biostats.bepress.com/jhubiostat/paper115/},
volume = {0},
year = {2006}
}
@article{Munzel2001,
abstract = {A general nonparametric approach to asymptotic multiple test procedures$\backslash$nis proposed which is based on relative effects and which includes$\backslash$ncontinuous as well as discontinuous distributions. The results can$\backslash$nbe applied to all relevant multiple testing problems in the one-way$\backslash$nlayout and include the well known Steel tests as special cases. Moreover,$\backslash$na general estimator for the asymptotic covariance matrix is considered$\backslash$nthat is consistent even under alternative. This estimator is used$\backslash$nto derive simultaneous confidence intervals for the relative effects$\backslash$nas well as a test procedure for the multiple nonparametric Behrens-Fisher$\backslash$nproblem.},
annote = {Mirar muy bien. Tiene paquete en R. Los ejemplos permiten ver que no piensa en muchos niveles para el factor.},
author = {Munzel, Ullrich and Hothorn, Ludwig a.},
doi = {10.1002/1521-4036(200109)43:5<553::AID-BIMJ553>3.0.CO;2-N},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Munzel, Hothorn - 2001 - A unified approach to simultaneous rank test procedures in the unbalanced one-way layout.pdf:pdf},
isbn = {0323-3847},
issn = {03233847},
journal = {Biometrical Journal},
keywords = {Behrens-Fisher problem,Multiple test procedure,Nonparametric,Simultaneous confidence intervals,Ties},
number = {5},
pages = {553--569},
title = {{A unified approach to simultaneous rank test procedures in the unbalanced one-way layout}},
volume = {43},
year = {2001}
}
@article{Neath2006,
annote = {Aproximaci{\'{o}}n bayesiana al problema, leer y mirar cuidadosamente.

Hace uso de modelo normal homoced{\'{a}}stico.

Se plantea la idea de las particiones.

No s{\'{e}} c{\'{o}}mo obtienen los valores para seleccionar (me interesa?)},
author = {Neath, Andrew a and Cavanaugh, Joseph E},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Neath, Cavanaugh - 2006 - A Bayesian Approach to the Multiple Comparisons Problem.pdf:pdf},
journal = {Journal of Data Science},
keywords = {bayesian information criterion,hierarchical modelling,model},
pages = {131--146},
title = {{A Bayesian Approach to the Multiple Comparisons Problem}},
volume = {4},
year = {2006}
}
@article{Ramsay1991,
abstract = {Multivariate data analysis permits the study of observations which are finite sets of numbers, but modern data collection situations can involve data, or the processes giving rise to them, which are functions. Functinal data analysis involves infinite dimensional processes and/or data. The paper shows how the theory of L-splines can support generalizations of linear modelling and principal components analysis to samples drawn from random functions. Spline smoothing rests on a partition of a function space into two orthogonal subspaces, one of which contains the obvious or structural components of variation among a set of observed functions, and the other of which contains residual components. This partitioning is achieved through the use of a linear differential operator, and we show how the theory or polynomial splines can be applied more generally with an arbitrary operator and associated boundary constraints. These data analysis tools are illustrated by a study of variation in temperature-precipitation patterns among some Canadian weather-stations.},
author = {Ramsay, J.O. and Dalzell, C.J.},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramsay, Dalzell - 1991 - Some Tools for Functional Data Analysis.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
keywords = {Differential Operator,Functional Principal Component,Functional linear model,L-splines,Nonparametric Regression,Smoothing},
number = {3},
pages = {539--572},
title = {{Some Tools for Functional Data Analysis}},
url = {http://www.jstor.org/stable/2345586},
volume = {53},
year = {1991}
}
@article{Rencher,
author = {Rencher, Alvin C},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rencher - Unknown - Methods of Multivariate Analysis Second Edition.pdf:pdf},
isbn = {0471418897},
title = {{Methods of Multivariate Analysis Second Edition}}
}
@article{emd,
abstract = {W troduce a metric bet een t o distributions that w ein w w e call the Earth Movers Distanc e EMD The EMD is based on the minim al cost thatm ust be paid to transform one distribution in to the other in a precise sense W e sho w that the EMD has attractiv e properties for con ten tbased image retriev al The most importan t one as w e sho w is that it matc hes perceptual similarit y better than other distances used for image retriev al The EMD is based on a solution to the transportation problem from linear optimization for whic h ecien t algorithms are a ailable and also allo v ws naturally for partial matc hing It is more robust than histogram matc hing tec hniques in that it can operate on v ariablelength represen tations of the distributions that a oid v quan tization and other binning problems t ypical of histograms When used to compare distributions with the same o erall mass the EMD is a true metric In this paper w v e focus on applications to color and texture and w e compare the retriev al performance of the EMD with that of other distances},
author = {Rubner, Yossi and Tomasi, Carlo and Guibas, Leonidas J},
doi = {10.1023/A:1026543900054},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rubner, Tomasi, Guibas - 2000 - The Earth Mover ' s Distance as a Metric for Image Retrieval.pdf:pdf},
isbn = {0780393325},
issn = {0920-5691},
journal = {Work},
keywords = {color,earth mover,image retrieval,perceptual metrics,s distance,texture},
number = {2},
pages = {1--20},
title = {{The Earth Mover ' s Distance as a Metric for Image Retrieval}},
url = {http://www.springerlink.com/index/W5515K817681125H.pdf},
volume = {40},
year = {2000}
}
@article{Showcase2004,
abstract = {CATS—clustering after transformation and smoothing—is a technique for nonparametrically estimating and clustering a large number of curves. Our motivating example is a genetic microarray experiment, but the method is very general. The method includes transformation and smoothing multiple curves, multiple nonparametric testing for screening out flat curves, clustering curves with similar shape, and nonparametrically inferring the clustering estimation error rate.},
author = {Serban, Nicoleta and Wasserman, Larry},
doi = {10.1198/016214504000001574},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Showcase et al. - 2004 - CATS Clustering After Transformation and Smoothing.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Clustering,Clustering error rate,False discovery rate,Genetic microarrays,Multiple testing,Smoothing},
number = {471},
pages = {990--999},
title = {{CATS: Clustering After Transformation and Smoothing}},
url = {http://repository.cmu.edu/statistics http://amstat.tandfonline.com/doi/abs/10.1198/016214504000001574},
volume = {100},
year = {2005}
}
@article{Sun,
abstract = {This paper proposes an informative exploratory tool, the functional boxplot, for visualizing functional data, as well as its generalization, the enhanced functional boxplot. Based on the center outwards ordering induced by band depth for functional data, the descriptive statistics of a functional boxplot are: the envelope of the 50{\%} central region, the median curve and the maximum non-outlying envelope. In addition, outliers can be detected in a functional boxplot by the 1.5 times the 50{\%} central region empirical rule, analogous to the rule for classical boxplots. The construction of a functional boxplot is illustrated on a series of sea surface temperatures related to the El Ni˜ no phenomenon and its outlier detection performance is explored by simula- tions. As applications, the functional boxplot and enhanced functional boxplot are demonstrated on children growth data and spatio-temporal U.S. precipitation data for nine climatic regions, respectively.},
author = {Sun, Ying and Genton, Marc G},
doi = {10.1198/jcgs.2011.09224},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sun, Genton - 2010 - Functional Boxplots.pdf:pdf},
isbn = {1061-8600},
issn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Depth,Functional data,Growth data,Precipitation,data,depth,functional data,growth data,precipitation data,space,time,visualization},
number = {2},
pages = {1--19},
title = {{Functional Boxplots}},
volume = {20},
year = {2010}
}
@misc{Tucker,
author = {Tucker, Howard G.},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tucker - Unknown - A Generalization of the Glivenko-Cantelli Theorem.pdf:pdf},
title = {{A Generalization of the Glivenko-Cantelli Theorem}}
}
@article{GCTHEO,
annote = {From Duplicate 1 (A Generalization of the Glivenko Cantelli Theorem - Tucker, H G)

From Duplicate 2 (A Generalization of the Glivenko Cantelli Theorem - Tucker, H G)

El teorema de glivenko Cantelli.

Mirar si es multivariado.},
author = {Tucker, Howard G.},
doi = {10.1214/193940307000000455},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tucker - 1959 - A Generalization of the Glivenko Cantelli Theorem.pdf:pdf;:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tucker - Unknown - A Generalization of the Glivenko-Cantelli Theorem.pdf:pdf},
isbn = {978-0-940600-74-4},
journal = {The Annals of Mathematical Statistic},
number = {3},
pages = {828--830},
title = {{A Generalization of the Glivenko-Cantelli Theorem}},
url = {http://projecteuclid.org/euclid.imsc/1207580085},
volume = {30},
year = {1959}
}
@article{WARD,
abstract = {A procedure for forming hierarchical groups of mutually exclusive subsets, each of which has members that are maximally similar with respect to specified characteristics, is suggested for use in large-scale (n{\textgreater}100) studies when a precise optimal solution for a specified number of groups is not practical. Given n sets, this procedure permits their reduction to n-1 mutually exclusive sets by considering the union of all possible n(n-1)/2 pairs and selecting a union having a maximal value for the functional relation, or objective function, that reflects the criterion chosen by the investigator. By repeating this process until only one group remains, the complete heirarchical structure and a quantitative estimate of the loss associated with each stage in the grouping can be obtained. A general flowchart helpful in computer programming and a numerical exple are included.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Ward, Joe H and {Ward Jr}, J},
doi = {10.1080/01621459.1963.10500845},
eprint = {arXiv:1011.1669v3},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ward - 1963 - Hierarchical Grouping to Optimize an Objective Function.pdf:pdf},
isbn = {01621459},
issn = {01621459},
journal = {Journal of the American Statistical Association},
number = {301},
pages = {236--244},
pmid = {600},
title = {{Hierarchical grouping to optimize an objective function}},
url = {http://www.jstor.org http://www.jstor.org/stable/2282967 http://www.jstor.org/page/},
volume = {58},
year = {1963}
}
@article{Cramer1973,
abstract = {Computer simulation techniques were used to study the Type I and Type Ill error rates and the correct decision rates for ten pairwise multiple comparison procedures. Results indicated that Scheffh's test, Tukey's test, and the Student-Newman-Keuls test are less ap- propriate than either the least significant difference with the restric- tion that the analysis of variance F value be significant at or = .05, two Bayesian modifications of the least significant difference, or Duncan's multiple range test. Because of its ease of application, many researchers may prefer the restricted least significant difference. 1.},
annote = {From Duplicate 2 (An Evaluation of Ten Pairwise Multiple Comparison Procedures by Monte Carlo Methos - Cramer, S G; Swanson, M R)

Evaluaci{\{}{\'{o}}{\}}n de 10 pruebas distintas. Recopilaci{\{}{\'{o}}{\}}n.},
author = {Cramer, S G and Swanson, M R and Carmer, S G and Swanson, M R},
doi = {10.2307/2284140},
file = {:home/julian/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cramer, Swanson - 1973 - An Evaluation of Ten Pairwise Multiple Comparison Procedures by Monte Carlo Methos.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {,Monte Carlo Method,Statistics},
number = {341},
pages = {66--74},
title = {{An evaluation of ten pairwise multiple comparison procedures by Monte Carlo methods}},
volume = {68},
year = {1973}
}
