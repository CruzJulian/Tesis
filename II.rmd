---
title: "Fundamentos"
author: "Julian Cruz"
output: 
  pdf_document:
    keep_tex: true
    toc: false
    number_sections: true
bibliography: Biblio.bib
csl: apa.csl
linkcolor: blue

---

# Nube de puntos

## Definiciones iniciales

El objeto de estudio se denomina nube de puntos. En el argot estadístico una nube de puntos es un concepto intuitivo, que corresponde de alguna manera a una colección finita en un espacio euclidiano. Muchas veces los valores presentan una estructura de pesos muestrales o factores de expansión asociados. Estos conceptos se formalizan a continuación.

Sea $\Omega$ un conjunto cualquera fijo, espacio de Banach a menos que se especifique lo contrario, y $\mathcal{B}$ su $\sigma$-álgebra de Borel. Las siguientes son directrices de notación, acuerdos y definiciones iniciales:

 - Familia [@Shao, definición 2.1]: Un conjunto de medidas de probabilidad sobre $(\Omega, \mathcal{B})$ se denomina familia y se nota $\mathcal{P}$. Siempre es posible indexar mediante $\mathcal{P}$ un espacio $\Theta$ que se denomina espacio de parámetros. Una familia $\mathcal{P}$ con un espacio de parámetros $\Theta$ de dimensión finita $d$, se denomina familia paramétrica. Una familia $\mathcal{P}$ cuyo espacio de parámetros $\Theta$ es neceariamente de dimensión infinita se denomina familia no paramétrica. Toda familia paremétrica está contenida en una familia no paramétrica, asímismo toda familia no paramétrica $\mathcal{P}$ contiene familias paramétricas. Toda familia se puede indexar a sí misma, en este sentido una medida de probabilidad puede ser un parámetro de si misma.

 - El conjunto de todas las medidas de probabilidad sobre $(\Omega, \mathcal{B})$ se nota $\mathbb{P}$. Dada una medida $\lambda$ sobre $(\Omega, \mathcal{B})$ se nota $\mathbb{P}_\lambda$ el conjunto de todas las medidas de probabilidad sobre $(\Omega, \mathcal{B})$ absolutamente contínuas con respecto a $\lambda$. Es posible indexar este conjunto usando el conjunto de sus derivadas con respecto a $\lambda$, no obstante se trata en general de una familia no paramétrica.

 - En adelante $\int$ representa la integral de Bochner. Se trata de una generalización de la integral de Lebesgue para funciones con valores en espacios de Banach. Al respecto, @Cohn hace un repaso claro y conciso.^[El uso de la integral de Bochner enriquece la construcción teórica y evita el uso del concepto de vectores aleatorios.] Es importante tener en cuenta que la definición de integral incluye los casos divergentes, es decir, los valores $\infty$ y $-\infty$ están contemplados como posibles resultados de una integral.

 - Dados dos números naturales $a$ y $b$, se nota $a:b$ al intervalo de números naturales entre $a$ y $b$ inclusive.

 - Salvo se especifique lo contrario, se usarán el símbolo $\wp$ para notar la $\sigma$-álgebra discreta en tanto el contexto sea claro.
 
 - El símbolo $\ddot{\mu}$ se reserva para la medida cardinal; el símbolo $\ddot{\lambda}$, para la de Lebesgue.
 
 - Se nota $\mathcal{P}_n$ a la familia de todas las medidas de probabilidad sobre $(1:n, \wp)$. 
 
 - Sea $p$ un elemento de $\mathcal{P}_n$, es decir, una medida de probabilidad sobre $(1:n, \wp)$. Una función $s$ del espacio de probabilidad $(1:n,\wp, p)$ en el espacio medible, $(\Omega, \mathcal{B})$ se denomina nube de puntos.

 - Una nube de puntos $s$ es función simple y medible. Siendo función, tiene dominio $Dom(s)$, rango $Ran(s)$, y en virtud de ser medible tiene una medida asociada $P_s$ sobre $(\Omega, \mathcal{B})$.

 - Dada una nube de puntos $s$ su tamaño es el máximo de su dominio: $n_s := \max(Dom(s))$.
 
 - El conjunto de todas las nubes de puntos posibles se nota por $\textbf{S}$. En otras palabras: $\textbf{S} = \{ s: (1:n, \wp, p) \rightarrow (\Omega, \mathcal{B}) \mid n \in \mathbb{N} \land p \in \textbf{P}_n\}$.
 
 - Una función medible que toma valores en un espacio de Banach se denomina variable aleatoria.^[Si bien el uso de variable aleatoria está destinado a funciones medibles de valor real, la presentación de un concepto más amplio obedece al caracter generalizado y generalizante de la construcción teórica.]
 
 - Dada una variable aleatoria $X$ su valor esperado y varianza, $E$ y $Var$, están dados por: $E(X) = \int X dP$ y $Var(X) = E(X^2) - E(X)^2$. Estos valores no siempre son finitos.
 
 - Se definen las funciones $\dddot{E}$ y $\dddot{Var}$, valor esperado muestral y varianza muestral: $\dddot{E}(s) = \int s dp$ y $\dddot{Var}(s) = \dddot{E}(s^2) - \dddot{E}(s)^2$.

De esta manera queda formalizado por completo el concepto de nubes de puntos. Los ítemes anteriores a pesar de ser triviales deben ser comprendidos a cabalidad, se sugiere un estudio detenido de los mismos para ver sus implicaciones directas. De acuerdo a la estructura propuesta, una nube de puntos $s$ tiene tamaño y probabilidades asociadas. En el uso cotidiano se suelen usar medidas de probabilidad uniformes cuya notación, $\ddot{p}$, se argumenta más adelante. Las medidas $\ddot{p}$ dan a cada punto un peso de $\frac{1}{n}$, sin embargo no son la única opción en temas de modelado.

Todo el fundamento teórico se ha escrito usando la integral de Bochner^[@Cohn]. Al respecto es importante notar que, salvo se especifique lo contrario, $\Omega$ es un espacio de Banach. Es decir, un espacio vectorial normado y completo [@Caicedo, definición 1.68]. De esta forma los resultados mostrados son válidos tanto para el caso univariado como el multivariado.

Es posible ver que el valor esperado y la varianza muestrales $\dddot{E}$ y $\dddot{Var}$ son funciones de $\textbf{S}$ en $\Omega$. El valor esperado muestral de $s$ siempre existe y está dado por $\dddot{E}(s) = \sum_{i=1}^{n_s} p(\{i\})s(i)$. Que en algunos ámbitos se denomina media muestral. Asímismo, la varianza de $s$ es $Var(s) = \sum_{i=1}^{n_s} p(\{i\})(s(i) - E(s))^2$. Que en algunos ámbitos se denomina varianza poblacional.^[Evidentemente los nombres tradicionales de estas cantidades no coinciden con los aquí puestos. No se volverán a mencionar para no dar lugar a confusiones.]

## Medida de probabilidad empírica

Se define la función $\mathfrak{P}$ de $\textbf{S}$ en $\mathbb{P}$ como sigue:

\begin{align*}
\mathfrak{P}: & \textbf{S} \longrightarrow \mathbb{P}\\
& s \mapsto \mathfrak{P}(s) := P_s
\end{align*}

donde

\begin{align*}
P_s: & \mathcal{B} \longrightarrow \mathbb{R} \\
& A \mapsto P_s(A) := p(s^{-1}(A))
\end{align*}

La función $\mathfrak{P}$ asigna a cada $s \in \textbf{S}$ su medida de probabilidad asociada. Esta medida de probabilidad se denomina medida de probabilidad empírica y es el centro de discusión del presente estudio.

## Ejemplos

Una medida de probabilidad $p$ sobre $(1:n, \wp)$ queda definida completamente a partir de los valores $p(\{i\})$. Así, es posible especificar una nube de puntos listando los valores de $s(i)$ y de $p(\{i\})$. Por ejemplo para $(\mathbb{R}, \mathcal{B})$, los valores $s = (1, 7, 3, 5)$, $p = (0.3, 0.2, 0.2, 0.3)$ definen una nube de puntos.

Dado un conjunto cualquiera $\Omega = \{a, b, c\}$. Una nube de puntos con valores en $(\Omega, \wp)$ se denomina nube de puntos categórica. En este caso $\Omega$ no es un espacio de Banach y la integración no está definida, por lo cual no es posible hablar de valores esperados. Muchas veces sucede que un espacio muestral está formado por una parte numérica, y otra categórica, es decir $\Omega = \Omega_N \times \Omega_C$, con $\Omega_N$ espacio de Banach.

Sea $\Omega = \mathbb{R}\times\mathbb{R}\times\mathbb{R}\times\mathbb{R}\times \{ `r paste(unique(iris$Species), collapse = ", ")` \}$ y $\mathcal{A} = \mathcal{B}\times\mathcal{B}\times\mathcal{B}\times\mathcal{B}\times\wp$. Iris [@IrisData1935, @FISHER_IRIS] es una nube de puntos de $(1:150, \wp, \ddot{p})$ en $(\Omega, \mathcal{A})$.

Sea $(\Omega, \mathcal{B})$ un espacio de Banach cualquera fijo. Un subconjunto $A$ de $\Omega$ se dice convexo si toda nube de puntos $s$ con valores en $A$ tiene su valor esperado muestal $E(s)$ en $A$.

# Propiedades

## Restricciones

$\textbf{S}$ es un conjunto muy interesante. Es posible realizar algunas restricciones.

 - En el espacio de medida $(\mathbb{N}, \wp, \mu)$, para cada número natural $n$ existe una única medida de probabilidad $p_{\mu, n}$ generada por $\mu$ sobre $(1:n, \wp)$, es: $p_{\mu,n}(A) = \frac{\mu(A)}{\mu(1:n)}$. Así $\textbf{S} |_\mu$ es el subconjunto de $\textbf{S}$ cuyos elementos $s$ tienen como dominio $(1:n, \wp, p_{\mu,n})$ para algún $n$. Este tipo de restricción no genera una partición sobre $\textbf{S}$, pues las restricciones no son necesariamente disjuntas. En particular las restricciones finitas de $\ddot{\mu}$ se notan por $\ddot{p}$. Es evidente que $\ddot{p}$ es una medida de probabilidad uniforme.
 
 - Sea $n$ un entero positivo fijo, $\textbf{S} |_n$ es el subconjunto de $\textbf{S}$ cuyos elementos $s$ tienen tamaño $n$. Esta restricción genera una partición de $\textbf{S}$.

 - $\textbf{S} |_{\mu,n}$ es la restricción de $\textbf{S}$ cuyos elementos $s$ tienen tamaño $n$ y probabilidad $p_{\mu, n}$. Esta restricción genera una partición de $\textbf{S} |_{\mu}$

## Particiones

A continuación se muestran algunas particiones.

 - $\textbf{S}/Ran$ corresponde a la partición de $\textbf{S}$ inducida por el rango $Ran(s)$. Dos nubes de puntos $s_1$ y $s_2$ pertenecen a la misma clase si $Ran(s_1) = Ran(s_2)$.

 - $\textbf{S}/\dddot{E}$ corresponde a la partición de $\textbf{S}$ inducida por la función valor esperado muestral. Dos nubes de puntos $s_1$ y $s_2$ pertenecen a la misma clase si $\dddot{E}(s_1) = \dddot{E}(s_2)$.

 - $\textbf{S}/\dddot{Var}$ corresponde a la partición de $\textbf{S}$ inducida por la función varianza muestral. Dos nubes de puntos $s_1$ y $s_2$ pertenecen a la misma clase si $\dddot{Var}(s_1) = \dddot{Var}(s_2)$.

 - $\mathbb{S} := \textbf{S}/\mathfrak{P}$ corresponde a la partición de $\textbf{S}$ inducida por $\mathfrak{P}$. Además, se dice que dos nubes de puntos $s_1$ y $s_2$ son equivalentes si son iguales en $\mathbb{S}$ y se nota $s_1 \equiv s_2$. $\mathbb{S}$ es inmune a permutaciones. Dada una permutación $j$ tal que $s_1(i) = s_2(j)$ entonces $s_1 \equiv s_2$. Esta ultima partición implica las anteriores: Dos nubes de puntos equivalentes $s_1 \equiv s_2$ tienen el mismo rango, el mismo valor esperado y la misma varianza. Esto no se cumple para tamaño.

## Proyecciones

Dados dos números naturales $i$ y $n$, con $i \leq n$, definimos la proyección $i$-ésima sobre $\textbf{S} |_n$ así:

\begin{align}
X_i: &\textbf{S} |_n \longrightarrow \Omega\\
&s \mapsto X_i(s) := s(i)
\end{align}

Dado que la restricción $\textbf{S} |_n$ genera una partición sobre $\textbf{S}$ es posible extender $X_i$ a todo $\textbf{S}$ teniendo en cuenta que $X_i(s)$ no está definido cuando $i > n_s$.

# Nebulosa

## Definición (Nebulosa)

Sean los espacios de medida $(\mathbb{N}, \wp, \mu)$ y $(\Omega, \mathcal{B}, P)$. Dados $n$ en los naturales y $(\Omega^n, \mathcal{B}^n, P^n)$ el espacio de medida producto existe una biyección $I$ entre $\Omega^n$ y $\textbf{S} |_{\mu,n}$. Esto dota a $\textbf{S} |_{\mu,n}$ de una medida de probabilidad homóloga a $P^n$ generando el espacio de probabilidad $(\textbf{S} |_{\mu,n}, \mathcal{B}^n, P^n)$. Este espacio de medida se denomina una nebulosa de $(\Omega, \mathcal{B}, P)$.^[El uso de la palabra nebulosa corresponde a la imagen de una nebulosa como un conjunto de nubes, sin embargo es pertinente enfatizar que la definición incluye la estructura de medida.]

Como se ve, $(\Omega, \mathcal{B}, P)$ tiene infinitas nebulosas, dependiendo de la medida $\mu$ y del tamaño $n$. Una función medible $f$ de $(\textbf{S} |_{\mu, n}, \mathcal{B}^n, P^n)$ en $\mathbb{R}$ tiene integral $\int f dP^n$. En particular la proyeción $i$-ésima $X_i$, definida sobre $(\textbf{S} |_{\mu,n}, \mathcal{B}^n, P^n)$, es medible, por lo tanto está definida su integral.

## Lemas

Dada una función medible $f$ de $(\Omega, \mathcal{B}, P)$ en $\mathbb{R}$, a raíz de la definición de la medida producto $P^n$ se tiene que:

\begin{gather}
\int f \circ X_i dP^n = \int f dP
\end{gather}

Adicionalmente, la definición propuesta de nebulosa hace posible establecer una medida sobre $\textbf{S} |_{\mu} = \bigcup\limits_{n = 1}^\infty \textbf{S} |_{\mu,n}$:

\begin{align}
P^*: &\bigcup\limits_{n=0}^\infty \mathcal{B}^n \longrightarrow \mathbb{R}\\
&S \mapsto P^*(S) = \sum\limits_{i=1}^\infty \mu(\{i\})P^n(S\cap \textbf{S} |_n) 
\end{align}

Como corolario, resulta fácil demostrar que $P^*(\textbf{S} |_{\mu,n}) = \mu(\{n\})$.

Como es de esperarse, una función medible $f$ de $(\textbf{S} |_\mu, \sigma(P^*), P^*)$ en un espacio de Banach $\Omega'$ tiene integral $\int f dP^*$. Como consecuencia de los enunciados anteriores es posible representar esta integral como la suma de los valores esperados de sus restricciones de tamaño $n$, $f|_n$. Es decir, $\int f dP^* = \sum_{n=1}^\infty \mu(\{n\}) \int f|_n dP^n$.

Dada una función medible $f$ de $(\Omega, \mathcal{B}, P)$ en un espacio de Banach $\Omega'$ el valor esperado de su proyección $i$-ésima está dado por:

\begin{gather}
\int\limits_{\textbf{S} |_{\mu}} f \circ X_i dP^* = \sum\limits_{n = i}^\infty \mu(\{n\}) \int\limits_{\textbf{S} |_{\mu, n}} f \circ X_i dP^n = \mu(\mathbb{N}) \int f dP
\end{gather}

Sea el espacio de medida $(\mathbb{N}, \wp, \mu)$ y los espacios asociados $(1:n, \wp, p_{\mu, n})$, si los valores $\mu({i})$ son acotados pero $\mu(\mathbb{N})$ es infinito, entonces la sucesión $a_n = \sum_{i=1}^n \left(p_{\mu,n}(\{i\})\right)^2$ converge a cero.

Esto sucede porque $p_{\mu,n}(\{i\}) = \frac{\mu(\{i\})}{\mu(1:n)}$, de manera que si $k$ en $\mathbb{R}$ es una cota para los valores de $\mu(\{i\})$ con $i$ en $\mathbb{N}$, entonces

\begin{align}
a_n &= \sum_{i=1}^n \left(\frac{\mu(\{i\})}{\mu(1:n)}\right)^2\\
&= \frac{1}{(\mu(1:n))^2}\sum_{i=1}^n \left(\mu(\{i\})\right)^2\\
&\leq \frac{1}{(\mu(1:n))^2}\sum_{i=1}^n \mu(\{i\})\max_{j=1}^n\{\mu(\{j\})\}\\
&= \frac{1}{(\mu(1:n))^2} \max_{j=1}^n\{\mu(\{j\})\} \sum_{i=1}^n \mu(\{i\})\\
&= \frac{1}{(\mu(1:n))^2} \max_{j=1}^n\{\mu(\{j\})\} \mu(1:n)\\
&= \frac{\max_{j=1}^n\{\mu(\{j\})\}}{\mu(1:n)}\\
&\leq \frac{k}{\mu(1:n)}
\end{align}

Así que cuando $n$ aumenta $a_n$ tiende a cero.

## Teorema de valor esperado

Sean $(\textbf{S} |_{\mu,n}, \mathcal{B}^n, P^n)$ una nebulosa sobre $(\Omega, \mathcal{B}, P)$ un espacio de Banach de probabilidad cualquera fijo y la función identidad $I$ de $\Omega$ en sí mismo. La restricción de tamaño $n$ del valor esperado muestral $\dddot{E}|_n$ definido anteriormente:

\begin{align}
\dddot{E}|_n:  = &\textbf{S} |_{\mu, n} \longrightarrow \Omega\\
& s \mapsto \int s dp
\end{align}

Entonces

 - $\dddot{E}|_n$ está bien definido.
 - $\dddot{E}|_n$ es una variable aleatoria.
 - Su valor esperado, $E(\dddot{E}|_n) = \int I dP$.
 - Su varianza es $Var(\dddot{E}|_n) = Var(I)\sum_{i = 1}^n \left(p_{\mu, n}(\{i\})\right)^2$.

En efecto, $\dddot{E}|_n$ es una función de $(\textbf{S} |_{\mu,n}, \mathcal{B}^n, P^n)$ en $(\Omega, \mathcal{B}, P)$ dada por $\dddot{E}|_n = \int s dp$. Dado que todas las nubes de puntos $s$ en $(\textbf{S} |_{\mu,n}, \mathcal{B}^n, P^n)$ son funciones simples, todas resultan integrables: $\int s dp = \sum_{i=1}^n p(\{i\}) s_i$, o, usando proyecciones, $\int s dp = \sum_{i=1}^n p(\{i\}) X_i(s)$. Esto último es particularmente importante; cada proyección es variable aleatoria, en consecuencia $\dddot{E}|_n$, como suma de variables aleatorias, es variable aleatoria. Como resultado $\dddot{E}|_n$ es variable aleatoria y $(\Omega, \mathcal{B}, P)$ es une espacio de Banach, por consiguiente $\dddot{E}|_n$ tiene valor esperado $E(\dddot{E}|_n) = \int \dddot{E}|_n dP^n$. Entre las propiedades relevantes de las integrales de Riemman, de Lebesgue y de Bochner está la linealidad, en consecuencia $E(\dddot{E}|_n) = \sum_{i=1}^n p(\{i\}) \int X_i(s) dP^n$, que, factorizando y sumando, resulta igual a $\int I dP$. Así mismo la varianza de $\dddot{E}|_n$ corresponde a $Var\left(\sum_{i=1}^n p(\{i\}) X_i(s)\right)$ que es igual a $\sum_{i=1}^n (p(\{i\}))^2 Var(X_i(s))$ que a su vez es igual a $Var(I)\sum_{i = 1}^n \left(p_{\mu, n}(\{i\})\right)^2$.

A modo de corolario, el valor esperado del valor esperado muestral de una variable aleatoria coincide con su valor esperado. Es decir, dada una función medible $f: (\Omega, \mathcal{B}, P) \rightarrow \Omega'$. $\dddot{E}(f\circ s) = \sum_{i=1}^{n_s} p(\{i\})f(s(i))$ y  $E(\dddot{E}|_n \circ f) = \int f dP$. Esto se demuestra fácilmente viendo que $f\circ s$ es una nube de puntos sobre $\Omega'$, lo cual sitúa el problema en el contexto inmediatamente anterior.

Otra consecuencia del anterior teorema es que, si $P$ tiene primer y segundo momento finitos y los valores $\mu({i})$ son acotados pero $\mu(\mathbb{N})$ es infinito, entonces la sucesión $a_n = \sum_{i=1}^n \left(p_{\mu,n}(\{i\})\right)^2$ y por ende $Var(\dddot{E})$ convergen a cero. Usandoeste hecho y la desigualdad de Chevichev es posible probar (un caso particular de) la ley débil de los grandes números [@LBlanco]. Probar la ley débil y la ley fuerte de los grandes números excede los objetivos del estudio, sin embargo son resultados usados más adelante.

Particularmente si $A \in \mathcal{B}$ es un evento cualquiera fijo, la función característica $\chi_A(x)$ es una función medible, de manera que el valor esperado de su valor esperado muestral $E(\dddot{E}|_n(\chi_A))$ es su valor esperado $E(\chi_A)$.

## Teorema de Glivenko Cantelli

Sean $(\textbf{S} |_\mu, \mathcal{B}^n, P^n)$ una nebulosa sobre $(\Omega, \mathcal{B}, P)$ un espacio de Banach de probabilidad cualquera fijo, $(\mathbb{N}, \wp, \mu)$ con los valores $\mu({i})$ acotados pero $\mu(\mathbb{N})$ infinito, $s$ una nube de puntos cualquiera en $(\textbf{S} |_{\mu,n}, \mathcal{B}^n, P^n)$ y $\dddot{E}|_n$ la restricción de tamaño $n$ del valor esperado muestral definido anteriormente.

$P_s$, la medida de probabilidad empírica de $s$ converge puntualmente a $P$ cuando $n_s$ tiende a infinito.

Para un evento cualquiera $A \in \mathcal{B}$ se tiene por definición que $P_s(A) = \int \chi_A dp$, que es igual a $\dddot{E}|_{n_s}(\chi_A)$, variable aleatoria de primer y segundo momentos finitos, cuyo valor esperado $E(\dddot{E}|_{n_s}(\chi_A))$ es igual a $E(\chi_A)$, que a su vez es igual a $\int \chi_A dP$, por definición $P(A)$. Resumiendo, el valor esperado de $P_s(A)$ es $P(A)$, al cual converge a medida que el tamaño de $s$ aumenta, si los valores $\mu({i})$ son acotados pero $\mu(\mathbb{N})$ es infinito, por la ley débil de los grandes números.

# Distancias

La estructura construida hasta el momento tiene por objetivo analizar las características generales de las nubes de puntos. En particular pretende definir formalmente distancias entre nubes de puntos, sin embargo esta tarea no ha resultado tan sencilla como el resto. El desarrollo presentado a continuación permite establecer las propiedades matemáticas que dan sentido a toda la tesis.

## Función de densidad general

Sea $(\Omega, \mathcal{B}, \lambda)$ un espacio de medida cualquiera fijo. Sea $g$ una función de $\Omega$ en $\mathcal{B}$ que a cada elemento $x$ de $\Omega$ le asigna un evento $g(x)$, tal que $\mathcal{B}$ coincide con el álgebra generada por el rango de $f$. Es decir $\sigma(g(\Omega)) = \mathcal{B}$. Entonces $g$ se denomina función elemental.

Sea $P$ una medida de probabilidad sobre $(\Omega, \mathcal{B})$ y $F = P \circ g$. $F$ es una función de $\Omega$ en $\mathbb{R}$ y se denomina función de densidad general asociada a $g$.

Por ejemplo, sobre $(\mathbb{N}, \wp, \ddot{\mu})$ se define la función elemental $g$, que a cada elemento le asigna su conjunto unitario: $g(i) = \{i\}$, de manera que efectivamente $\sigma(g(\mathbb{N})) = \wp$.

Sea $P$ la medida de probabilidad de Poisson de parámetro $1$, entonces la función de densidad general asociada a $g$ está dada por

$$ F(i) = P(g(i)) = \frac{dP}{d\ddot{\mu}}(i)$$

Otro ejemplo, sobre $(\mathbb{R}, \mathcal{B}, \ddot{\lambda})$ se define la función elemental $g$, que a cada elemento le asigna su cola abierta a izquierda: $g(x) = (-\infty, x)$, de manera que efectivamente $\sigma(g(\mathbb{R})) = \mathcal{B}$.

Sea $P$ la medida de probabilidad exponencial de parámetro $1$, entonces la función de densidad general asociada a $g$^[Cuando $\Omega = \mathbb{R}$ y $g(x) = (-\infty, x)$ la función de densidad general asociada a $g$, $F = P \circ g$, se denomina función de densidad acumulada.] está dada por

$$ F(i) = P(g(i)) = \int \limits_{(-\infty, x)} \frac{dP}{d\ddot{\lambda}}(t) d\lambda(t) = \chi_{(-\infty, x)}(1 - e^{-x}) $$

Dados $(\Omega, \mathcal{B}, \lambda)$ un espacio de medida cualquiera fijo y una función elemental $g$, sí dos medidas de probabilidad $P_1$ y $P_2$ tienen la misma función de densidad general entonces son iguales entre sí.

Dados $(\Omega, \mathcal{B}, P, \lambda)$ un espacio de medida cualquiera fijo, una función elemental $g$ y una nube de puntos $s: (1:n, \wp, p) \rightarrow (\Omega, \mathcal{B}, \lambda)$. La medida de probabilidad empírica $P_s$ definida previamente, tiene una función de densidad general, que se denomina función de densidad general (acumulada) empirica.

El teorema de Glivenko Cantelli implica la convergencia puntual de la función de densidad general empírica (acumulada empírica) a la función de densidad general (acumulada) conforme el tamaño muestral $n_s$ aumenta. En consecuencia es posible pensar que nubes de puntos sobre el mismo espacio son cercanas en tanto su tamaño aumenta. Para poder formalizar estas conclusiones es necesario definir distancias entre nubes de puntos.

Varias distancias entre funciones requieren de integrabilidad, por esto es necesario examinar la integrabilidad de las funciones de densidad generales respecto a la medida $\lambda$ antes de proseguir. Tomando primero el caso particular de las medidas de probabilidad empírica $P_s$ es posible ver que las funciones de densidad general empírica son funciones simples. Teniendo en cuenta la convergencia de $P_s$ a $P$, se tiene que cada función de densidad general es el límite de una sucesión de funciones de densidadd general empírica, como cada una de estas es una función simple, las funciones de densidad general son integrables.

## Primer acercamiento

La primera idea de una distancia entre nubes de puntos $\mathtt{d}$ puede estar asociada con la distancia entre sus funciones de densidad general empíricas. Intuitivamente, nubes de puntos muy diferentes producen medidas de probabilidad empírica muy diferentes, que a su vez producen funciones de densidad general empírica distintas; en consecuencia, medir cercanía entre funciones de densidad general empírica puede dar luces respecto a la cercanía entre nubes de puntos. O al menos esa es la propuesta EP-Means [@EPMEANS].

Sean $(\Omega, \mathcal{B})$ y $d$ una distancia entre funciones de $(\Omega, \mathcal{B})$ en $\mathbb{R}$. Dadas dos nubes de puntos $s_1$ y $s_2$, con sus medidas de probabilidad empírica $P_{s_1}$ y $P_{s_2}$ y sus funciones de densidad general empírica $f_{s_1}$ y $f_{s_2}$ se define la función $\mathtt{d}_0(s_1, s_2) =  d(f_{s_1}, f_{s_2})$.

Sin embargo $\mathtt{d}_0$ no es una distancia. Nubes de puntos equivalentes tienen medidas de pribabilidad empírica iguales y funciones de densidad general empírica iguales, por lo cual dos nubes de puntos distintas pueden tener distancia cero. En ese sentido $\mathtt{d}_0$ es una semidistancia.

Por otro lado es necesario examinar la incidencia del tamaño de las nubes de puntos en la asignación de una distancia a la luz de la convergencia. El teorema de Glivenko Cantelli implica que, a medida que el tamaño aumenta, las funciones de densidad general empírica convergen a la función de densidad acumulada del modelo. Al aumentar el tamaño de las nubes de puntos la varianza de la medida de probabilidad empírica disminuye. De manera ilustrativa es posible ver el espacio de nubes de puntos pequeñas como un mundo amplio y el espacio de nubes de puntos puntos de gran tamaño como un mundo bastante más estrecho, que se encoge conforme el tamaño aumenta. La distancia definida debe reflejar esto, es decir, dos nubes de puntos de tamaños bajos deben considerase cercanas más fácilmente que dos de tamaños altos.

## Teorema de corrección de distancias

Sea un espacio métrico $(V, d)$ y dos constantes $a > 0$ y $b > 0$, entonces la correción $d' = min(ad, d + b)$ es una distancia.

En efecto:

 - $d'(x, y) \geq 0$ para todo par $(x,y)$, pues $a > 1$, $b > 0$ y $d(x, y) \geq 0$.
 - Si $d'(x, y) = 0$ si y sólo si $\min(ad(x,y), d(x,y) + b) = 0$ si y sólo si $ad(x,y) = 0$, si y sólo si $d(x,y) = 0$, si y sólo si $x = y$.
 - La desigualdad triangular se tiene, pues $d'(x, y) \leq ad(x,y)$ y $d'(x, y) \leq d(x,y) + b$ por lo cual, sumando: $2d'(x, y) \leq ad(x,y) + d(x,y) + b\leq ad(x,z) + ad(z,y) + d(x,z) + b + d(z, y) + b \leq 2 \min(ad(x,z), d(x,z) + b) + 2\min(ad(z,y), d(z, y) + b) = 2d'(x,z) + 2d'(z,y)$
 

## Criterio de Cramer-von Misses generalizado controlado por tamaño entre nubes de puntos

Para finalizar el capítulo se define el criterio de distancia o cercania propuesto entre nubes de puntos. Como se aclaró en el capíitulo anterior, este criterio permitirá el uso de algoritmos basados en distancias y semidistancias en nubes de puntos. Se espera que el examen minucioso de los criterios de cercania o similaridad entre nubes de puntos sirva como insumo para fortalecer los modlos estadísiticos libres de distribución.

Sean $(\Omega, \mathcal{B})$, $d$ una distancia entre funciones de $(\Omega, \mathcal{B})$ en $\mathbb{R}$. Dadas dos nubes de puntos $s_1$ y $s_2$, con sus medidas de probabilidad empírica $P_{s_1}$ y $P_{s_2}$ y sus funciones de densidad general empírica $f_{s_1}$ y $f_{s_2}$ y tamaños $n_{s_1}$ y $n_{s_2}$; se define la función $\mathtt{d}(s_1, s_2) =  \min(h(n_{s_1}, n_{s_2})d(f_{s_1}, f_{s_2}), d(f_{s_1}, f_{s_2}) + 1)$.

$\mathtt{d}$ no es una distancia: nubes de puntos equivalentes tienen medidas de pribabilidad empírica iguales y funciones de densidad general empírica iguales, por lo cual dos nubes de puntos distintas pueden tener distancia cero. Tampoco es una semidistancia, pues $h(n_{s_1}, n_{s_2})$ no es constante, en conescuencia es posible que no cumpla con la desigualdad triangular en unos casos muy específicos. El caso contínuo puede examinarse a la luz de las funciones de densidad acumulada y acumulada empírica, no obstante los resultados teóricos son bastante más generales.

# Referencias